{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim\n",
    "\n",
    "# import cPickle as pickle\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm, tqdm_notebook, tnrange\n",
    "from S3_read_write import load_df_s3, save_df_s3\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas('Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'amazon-reviews-project'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Amazon Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = load_df_s3(bucket_name, 'amazon_reviews/reviews_data_clean', filetype='text', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585444, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape    # 585,444 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>categories_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0929619730</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>B-flax-D is a re...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dpes the job well</td>\n",
       "      <td>Contains Organic...</td>\n",
       "      <td>New Generation B...</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Studies show tha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fast shipping, g...</td>\n",
       "      <td>Everyone knows t...</td>\n",
       "      <td>Nutrihill Resver...</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I started taking...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bioavailability ...</td>\n",
       "      <td>Everyone knows t...</td>\n",
       "      <td>Nutrihill Resver...</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I tried Nutrihil...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Other Resveratro...</td>\n",
       "      <td>Everyone knows t...</td>\n",
       "      <td>Nutrihill Resver...</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I really liked t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I can't find thi...</td>\n",
       "      <td>Everyone knows t...</td>\n",
       "      <td>Nutrihill Resver...</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful           reviewText  overall              summary  \\\n",
       "0  0929619730  [0, 0]  B-flax-D is a re...      5.0    Dpes the job well   \n",
       "1  0978559088  [1, 1]  Studies show tha...      4.0  Fast shipping, g...   \n",
       "2  0978559088  [1, 1]  I started taking...      5.0  Bioavailability ...   \n",
       "3  0978559088  [0, 1]  I tried Nutrihil...      1.0  Other Resveratro...   \n",
       "4  0978559088  [0, 0]  I really liked t...      5.0  I can't find thi...   \n",
       "\n",
       "           description                title     categories_clean  \n",
       "0  Contains Organic...  New Generation B...  Health & Persona...  \n",
       "1  Everyone knows t...  Nutrihill Resver...  Health & Persona...  \n",
       "2  Everyone knows t...  Nutrihill Resver...  Health & Persona...  \n",
       "3  Everyone knows t...  Nutrihill Resver...  Health & Persona...  \n",
       "4  Everyone knows t...  Nutrihill Resver...  Health & Persona...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                 object\n",
       "helpful              object\n",
       "reviewText           object\n",
       "overall             float64\n",
       "summary              object\n",
       "description          object\n",
       "title                object\n",
       "categories_clean     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Health & Personal Care, Vitamins & Dietary Supplements, Multi & Prenatal Vitamins, Multiple Vitamin-Mineral Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Supplements, Antioxidants, Resveratrol',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Multi & Prenatal Vitamins, Multivitamins',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Vitamins, Vitamin B, B3 (Niacin)',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements, Green Tea',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Weight Loss, Supplements, Green Coffee Bean Extract',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Weight Loss, Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Supplements, Antioxidants, CoQ10',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements, Ginkgo Biloba'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.categories_clean.unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The catergories' list indicates that there may be some reviews in the dataset unrelated to health supplements.  Let's get rid of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Liturgy of St. John Chrysostom', 'Origins',\n",
       "       'Sounds of the Earth: Soft Ocean Sounds', 'Bali',\n",
       "       'Tranquil Waters', 'Bach: St. John Passion, BWV 245',\n",
       "       '21st Century Soul', 'Bodies for Strontium', \"John's Bunch\",\n",
       "       'An Evening of Paganini', \"John's Other Bunch\",\n",
       "       'Sus Mas Grandes Exitos', 'Complex Simplicity',\n",
       "       'Kidnapped By Neptune', 'Roman Chant / Easter Vespers', 'Dead 60s',\n",
       "       \"Cilla in the 60's\", 'Chromium', 'Letters From the Vitamin Sea',\n",
       "       'The Stinging Nettles', 'Tendres Annees 60', 'Wehiwehi Hawaii',\n",
       "       'none'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews.categories_clean.str.contains('CDs & Vinyl')].title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews[reviews.categories_clean.str.contains('CDs & Vinyl')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product titles shown above are all music albums/songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_filt = reviews[~(reviews.categories_clean.str.contains('CDs & Vinyl'))]   # remove rows with category including 'CDs & Vinyl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Health & Personal Care, Vitamins & Dietary Supplements, Multi & Prenatal Vitamins, Multiple Vitamin-Mineral Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Supplements, Antioxidants, Resveratrol',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Multi & Prenatal Vitamins, Multivitamins',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Vitamins, Vitamin B, B3 (Niacin)',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements, Green Tea',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Weight Loss, Supplements, Green Coffee Bean Extract',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Weight Loss, Supplements',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Supplements, Antioxidants, CoQ10',\n",
       "       'Health & Personal Care, Vitamins & Dietary Supplements, Herbal Supplements, Ginkgo Biloba'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_filt.categories_clean.unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>categories_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>B00009QP4Q</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>The company has ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lives up to its ...</td>\n",
       "      <td>Alpha Five's QLi...</td>\n",
       "      <td>none</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50015</th>\n",
       "      <td>B0002TIEQQ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I ordered this f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>waste of money</td>\n",
       "      <td>Self help tutori...</td>\n",
       "      <td>none</td>\n",
       "      <td>Health &amp; Persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin helpful           reviewText  overall              summary  \\\n",
       "3639   B00009QP4Q  [2, 2]  The company has ...      5.0  lives up to its ...   \n",
       "50015  B0002TIEQQ  [0, 0]  I ordered this f...      1.0       waste of money   \n",
       "\n",
       "               description title     categories_clean  \n",
       "3639   Alpha Five's QLi...  none  Health & Persona...  \n",
       "50015  Self help tutori...  none  Health & Persona...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_filt[reviews_filt.categories_clean.str.contains('Software')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_filt = reviews_filt[~(reviews_filt.categories_clean.str.contains('Software'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585179"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of reviews of pet-related products\n",
    "search_for = [' pet ', ' cat ', ' dog ']\n",
    "pattern = '|'.join(search_for)\n",
    "reviews_filt.title.str.contains(pattern, case=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Power - Mune Tuna Flavor Pet Herbal Supplement From Vetvittles.com',\n",
       "       'Power - Mune Tuna Flavor Pet Herbal Supplement From Vetvittles.com',\n",
       "       'Power - Mune Tuna Flavor Pet Herbal Supplement From Vetvittles.com',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'AniMed Witch Hazel 86-Percent Multi-Species Pet Supplement',\n",
       "       'Composure Liquid for Dogs and Cat (188 SERVINGS)'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_filt[reviews_filt.title.str.contains(pattern, case=False)]['title'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all pet products\n",
    "reviews_filt = reviews_filt[~(reviews_filt.title.str.contains(pattern, case=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned dataframe\n",
    "save_df_s3(df=reviews_filt, bucket_name=bucket_name, filepath='amazon_reviews/reviews_data_clean_v2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48501"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_filt.asin.nunique()     # 48,535 unique products and 585,179 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine One Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = reviews_filt.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0929619730'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.asin     # Amazon Standard Identification Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Generation B-Flax-D'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.title     # this is the product's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Health & Personal Care, Vitamins & Dietary Supplements, Multi & Prenatal Vitamins, Multiple Vitamin-Mineral Supplements'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.categories_clean   # previously filtered/curated categories of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contains Organic Cold-Milled Flaxseed\\nValuable source of soluble and insoluble fiber\\nProvides Omega-3 essential fats, and many other nutrients to help achieve and maintain optimal bowel function.\\n\\nContains Vitamin B12\\nB12 helps prevent nerve damage\\nB12 aids in healthy cell formation.\\nB12 helps prevent anemia\\n\\nContains Vitamin D\\nVitamin D assists the body in the absorption of important minerals like calcium.\\n\\nContains Seleno-yeast\\nA source of selenium, a mineral with powerful anti-viral and disease-fighting properties.\\n\\nContains Vitamin K2\\nMenaQ7TM provides vitamin K2 (menaquinone), extracted and concentrated from natto without solvents. Vitamin K2 prevents arterial calcification and promotes strong bones by improving cross-linking of osteocalcin, a protein found in bones. The amount here has been clinically shown not to interfere with blood anti-coagulant medication. \\n\\nServing Size:\\n1/4 Cup (30 Grams)\\n\\nServings Per Container:\\n30 Servings per container\\n\\nNet Wt. 32 oz / 2 lb (908 g)\\n\\nB-Flax-D is a 100% vegetarian product.\\n\\nDoes Not Contain:\\nContains no artificial colors or preservatives.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.description       # product description provided by the seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dpes the job well'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.summary      # review title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt around. Good product, good price, good results.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.reviewText   # review content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the actual review looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.overall     # the rating provided by the reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 0]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/amazon_review_screenshot.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"images/amazon_review_screenshot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start off using only the title (`summary`) and body (`reviewText`) of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 20.8 s, total: 36.3 s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = load_df_s3(bucket_name, filepath='amazon_reviews/reviews_data_clean_v2.feather', filetype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                 object\n",
       "helpful              object\n",
       "reviewText           object\n",
       "overall             float64\n",
       "summary              object\n",
       "description          object\n",
       "title                object\n",
       "categories_clean     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['helpful', 'overall', 'title', 'categories_clean', 'description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0929619730</td>\n",
       "      <td>B-flax-D is a regular at our house. It does it...</td>\n",
       "      <td>Dpes the job well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Studies show that Resveratrol is poorly absorb...</td>\n",
       "      <td>Fast shipping, good communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>I started taking this after both my parents di...</td>\n",
       "      <td>Bioavailability is the key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>I tried Nutrihill, but did not feel any of the...</td>\n",
       "      <td>Other Resveratrol Supplements are Better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>I really liked this product because it stayed ...</td>\n",
       "      <td>I can't find this product any longer, and I wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                         reviewText  \\\n",
       "0  0929619730  B-flax-D is a regular at our house. It does it...   \n",
       "1  0978559088  Studies show that Resveratrol is poorly absorb...   \n",
       "2  0978559088  I started taking this after both my parents di...   \n",
       "3  0978559088  I tried Nutrihill, but did not feel any of the...   \n",
       "4  0978559088  I really liked this product because it stayed ...   \n",
       "\n",
       "                                             summary  \n",
       "0                                  Dpes the job well  \n",
       "1                  Fast shipping, good communication  \n",
       "2                         Bioavailability is the key  \n",
       "3           Other Resveratrol Supplements are Better  \n",
       "4  I can't find this product any longer, and I wi...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each review, concatenate the review title and body\n",
    "df.reviewText = df.summary + '. ' + df.reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0929619730</td>\n",
       "      <td>Dpes the job well. B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Fast shipping, good communication. Studies show that Resveratrol is poorly absorbed when taken by pill, but lozenges are very effectively absorbed. Hardly any companies are selling lozenges. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Bioavailability is the key. I started taking this after both my parents died of cancer as it supposed to enhance your immune system - the story on 60 Minutes on resveratrol was incredibly inspirin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Other Resveratrol Supplements are Better. I tried Nutrihill, but did not feel any of the supposed health benefits. I started reading and realized that even though buccal delivery is the best, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>I can't find this product any longer, and I wish I could.. I really liked this product because it stayed in my mouth for a long time and I felt it was probably doing some good.  I take a number of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  0929619730   \n",
       "1  0978559088   \n",
       "2  0978559088   \n",
       "3  0978559088   \n",
       "4  0978559088   \n",
       "\n",
       "                                                                                                                                                                                                reviewText  \n",
       "0  Dpes the job well. B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt ...  \n",
       "1  Fast shipping, good communication. Studies show that Resveratrol is poorly absorbed when taken by pill, but lozenges are very effectively absorbed. Hardly any companies are selling lozenges. This ...  \n",
       "2  Bioavailability is the key. I started taking this after both my parents died of cancer as it supposed to enhance your immune system - the story on 60 Minutes on resveratrol was incredibly inspirin...  \n",
       "3  Other Resveratrol Supplements are Better. I tried Nutrihill, but did not feel any of the supposed health benefits. I started reading and realized that even though buccal delivery is the best, the ...  \n",
       "4  I can't find this product any longer, and I wish I could.. I really liked this product because it stayed in my mouth for a long time and I felt it was probably doing some good.  I take a number of...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 200)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the `summary` column now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0929619730</td>\n",
       "      <td>Dpes the job well. B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Fast shipping, good communication. Studies show that Resveratrol is poorly absorbed when taken by pill, but lozenges are very effectively absorbed. Hardly any companies are selling lozenges. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Bioavailability is the key. I started taking this after both my parents died of cancer as it supposed to enhance your immune system - the story on 60 Minutes on resveratrol was incredibly inspirin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>Other Resveratrol Supplements are Better. I tried Nutrihill, but did not feel any of the supposed health benefits. I started reading and realized that even though buccal delivery is the best, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0978559088</td>\n",
       "      <td>I can't find this product any longer, and I wish I could.. I really liked this product because it stayed in my mouth for a long time and I felt it was probably doing some good.  I take a number of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  0929619730   \n",
       "1  0978559088   \n",
       "2  0978559088   \n",
       "3  0978559088   \n",
       "4  0978559088   \n",
       "\n",
       "                                                                                                                                                                                                reviewText  \n",
       "0  Dpes the job well. B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt ...  \n",
       "1  Fast shipping, good communication. Studies show that Resveratrol is poorly absorbed when taken by pill, but lozenges are very effectively absorbed. Hardly any companies are selling lozenges. This ...  \n",
       "2  Bioavailability is the key. I started taking this after both my parents died of cancer as it supposed to enhance your immune system - the story on 60 Minutes on resveratrol was incredibly inspirin...  \n",
       "3  Other Resveratrol Supplements are Better. I tried Nutrihill, but did not feel any of the supposed health benefits. I started reading and realized that even though buccal delivery is the best, the ...  \n",
       "4  I can't find this product any longer, and I wish I could.. I really liked this product because it stayed in my mouth for a long time and I felt it was probably doing some good.  I take a number of...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Missing Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText.isnull().sum()    # 73 reviews have neither a review body text, nor a review title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reviews with no text\n",
    "df = df[~(df.reviewText.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.asin.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few actual review texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"works!. I've been using for the last month so far I've lost 6 pounds, great product, there's no taste so u can put it on anything,I love it!!\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText.iloc[np.random.randint(0, len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ganoderma lucidum works.. ganoderma was discovered through a sales representative and was recommended by a cardiologist for my husband after 4 bypasses.  This herb has proven and improved health for my husband.  We live in the south pacific below the equator, I thank you Amazon for carrying this herb as well as tongkat ali (gin ali) to where I can order online.  The last order received this month, Amazon indicated online products as the last two of the ganoderma left.  Is there another stock or supply when I am ready to order again?  Please inform.  Thank You.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText.iloc[np.random.randint(0, len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So far, so good. In my opinion this CoQ10 is a nice middle of the road product. Not a cheap pos but a decent, solid product.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText.iloc[np.random.randint(0, len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 584829 entries, 0 to 584901\n",
      "Data columns (total 2 columns):\n",
      "asin          584829 non-null object\n",
      "reviewText    584829 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df.reviewText.values)    # make an iterable to store only the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584829"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dpes the job well. B-flax-D is a regular at our house. It does its job simply and with good results. It is reasonable, lasts a long time, and is able to be obtained with free shipping if you hunt around. Good product, good price, good results. \n",
      "\n",
      "Fast shipping, good communication. Studies show that Resveratrol is poorly absorbed when taken by pill, but lozenges are very effectively absorbed. Hardly any companies are selling lozenges. This company promises 99% purity and has fast shipping and good communication. I can't comment on the quality of product because I'm not a chemist but they seem to be legitimate. \n",
      "\n",
      "Bioavailability is the key. I started taking this after both my parents died of cancer as it supposed to enhance your immune system - the story on 60 Minutes on resveratrol was incredibly inspiring. Doing some research on the Internet, it is indicated that taking resveratrol in lozenge form is preferable as it is broken down by stomach acids.  The ez-melt formula recommended in another review is OK, but it is dissolved in the mouth much more quickly than this lozenge formula, while dissolving more slowly is preferable according to my research.This product has the greatest side effect - since taking it, I haven't had colds or sore throats.  Soon after starting to take it every day, I was starting to come down with a cold, with all my usual symptoms, and was anticipating being very sick the next day, as is my usual pattern.  But I never did get as sick as anticipated - taking this product is the only reason I can come up with.  Since then, I've had no colds or sore throats - it has been great.  I recommend this product to everyone I know, and have given it as gifts to my family. \n",
      "\n",
      "Other Resveratrol Supplements are Better. I tried Nutrihill, but did not feel any of the supposed health benefits. I started reading and realized that even though buccal delivery is the best, the dose is too small in this supplement. I then tried Resveratrol 150 from ezmelts. It's also a lozenge (they call it melt) and it literally melts in your mouth. I have a lot more energy, and haven't been sick at all. I used to get colds and flus all the time before. You can find ezmelts here on amazon, ebay and a bunch of other suppliers. You can find it here:EZ Melts Resveratrol, Natural Grape Flavor, 60 Tablets \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at a few sample reviews\n",
    "for rev in text[:4]:\n",
    "    print(rev, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper functions below are from:\n",
    "\n",
    "http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use `gensim`'s `Phrases` class to detect natural combinations of words (like 'vanilla ice cream'), we need to format our text into a list of sentences, with each sentence being a list of words.  This process takes a large amount of processing time (for reference, the times shown under the cells are for running the tasks on a c5.18xlarge EC2 instance (equivalent spot fleet)), so `text` has been split into 3 parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Unigram Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584829"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text into 9 parts\n",
    "text_first  = text[:50000]\n",
    "text_second = text[50000:100000]\n",
    "text_third  = text[100000:150000]\n",
    "text_fourth = text[150000:300000]\n",
    "text_fifth  = text[300000:350000]\n",
    "text_sixth  = text[350000:400000]\n",
    "text_seventh= text[400000:450000]\n",
    "text_eighth = text[450000:500000]\n",
    "text_ninth = text[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [08:06, 102.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  50000\n",
      "current sent_num:  305895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rev_num = 0    # review tracker\n",
    "sent_num = 0   # sentence tracker\n",
    "unigram_sents_pos = [] # to store lists of lemmatized tokens for each sentence\n",
    "\n",
    "for parsed_review in tqdm(nlp.pipe(text_first, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305895"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_sents_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, [('dpe', 'NOUN'), ('the', 'DET'), ('job', 'NOUN'), ('well', 'ADV')]]\n",
      "[1, 2, [('b', 'NOUN'), ('flax', 'NOUN'), ('d', 'NOUN'), ('be', 'VERB'), ('a', 'DET'), ('regular', 'ADJ'), ('at', 'ADP'), ('-PRON-', 'ADJ'), ('house', 'NOUN')]]\n",
      "[1, 3, [('-PRON-', 'PRON'), ('do', 'VERB'), ('-PRON-', 'ADJ'), ('job', 'NOUN'), ('simply', 'ADV'), ('and', 'CCONJ'), ('with', 'ADP'), ('good', 'ADJ'), ('result', 'NOUN')]]\n",
      "[1, 4, [('-PRON-', 'PRON'), ('be', 'VERB'), ('reasonable', 'ADJ'), ('last', 'VERB'), ('a', 'DET'), ('long', 'ADJ'), ('time', 'NOUN'), ('and', 'CCONJ'), ('be', 'VERB'), ('able', 'ADJ'), ('to', 'PART'), ('be', 'VERB'), ('obtain', 'VERB'), ('with', 'ADP'), ('free', 'ADJ'), ('shipping', 'NOUN'), ('if', 'ADP'), ('-PRON-', 'PRON'), ('hunt', 'VERB'), ('around', 'ADV')]]\n",
      "[1, 5, [('good', 'ADJ'), ('product', 'NOUN'), ('good', 'ADJ'), ('price', 'NOUN'), ('good', 'ADJ'), ('result', 'NOUN')]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(unigram_sents_pos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN DET NOUN ADV</td>\n",
       "      <td>dpe the job well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN NOUN NOUN V...</td>\n",
       "      <td>b flax d be a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PRON VERB ADJ NO...</td>\n",
       "      <td>-PRON- do -PRON-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PRON VERB ADJ VE...</td>\n",
       "      <td>-PRON- be reason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ADJ NOUN ADJ NOU...</td>\n",
       "      <td>good product goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number  sentence_number          unigram_pos    unigram_sentences\n",
       "0              1                1    NOUN DET NOUN ADV     dpe the job well\n",
       "1              1                2  NOUN NOUN NOUN V...  b flax d be a re...\n",
       "2              1                3  PRON VERB ADJ NO...  -PRON- do -PRON-...\n",
       "3              1                4  PRON VERB ADJ VE...  -PRON- be reason...\n",
       "4              1                5  ADJ NOUN ADJ NOU...  good product goo..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sentences_savedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [08:04, 103.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  100000\n",
      "current sent_num:  616751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_second, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616751\n"
     ]
    }
   ],
   "source": [
    "print(len(unigram_sents_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [07:55, 105.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  150000\n",
      "current sent_num:  923642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_third, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150000it [23:51, 104.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  300000\n",
      "current sent_num:  1843092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_fourth, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [07:43, 107.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  350000\n",
      "current sent_num:  2144424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_fifth, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [07:46, 107.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  400000\n",
      "current sent_num:  2447985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_sixth, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [07:41, 108.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  450000\n",
      "current sent_num:  2754623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_seventh, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [08:04, 103.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  500000\n",
      "current sent_num:  3073060\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_eighth, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84829it [13:30, 104.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current rev_num:  584829\n",
      "current sent_num:  3605491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for parsed_review in tqdm(nlp.pipe(text_ninth, batch_size=20000, n_threads=72)):\n",
    "    rev_num += 1\n",
    "    for sent in parsed_review.sents:\n",
    "        sent_num += 1\n",
    "        # lemmatize tokens & save corresponding pos tag after filtering whitespace and punctuations\n",
    "        lemmatized_sent = [(token.lemma_, token.pos_) for token in sent if not (token.is_space or token.is_punct)]\n",
    "        unigram_sents_pos.append([rev_num, sent_num, lemmatized_sent])\n",
    "\n",
    "print('current rev_num: ', rev_num)\n",
    "print('current sent_num: ', sent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress...\n",
    "review_number = [row[0] for row in unigram_sents_pos]\n",
    "sentence_number = [row[1] for row in unigram_sents_pos]\n",
    "words_joined_all = []\n",
    "pos_joined_all = []\n",
    "for sent in unigram_sents_pos:\n",
    "    word_pos = sent[2]\n",
    "    word_list = [word for word, pos in word_pos]\n",
    "    pos_list = [pos for word, pos in word_pos]\n",
    "    words_joined = ' '.join(word for word in word_list)\n",
    "    pos_joined   = ' '.join(pos for pos in pos_list)\n",
    "    words_joined_all.append(words_joined)\n",
    "    pos_joined_all.append(pos_joined)\n",
    "    \n",
    "unigram_sentences_savedf = pd.DataFrame({'review_number': review_number,\n",
    "                                         'sentence_number': sentence_number,\n",
    "                                         'unigram_sentences': words_joined_all,\n",
    "                                         'unigram_pos': pos_joined_all})\n",
    "\n",
    "save_df_s3(unigram_sentences_savedf, bucket_name, 'amazon_reviews/unigram_sentences.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_savedf = load_df_s3(bucket_name, 'amazon_reviews/unigram_sentences.feather', filetype='feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605491"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_joined_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605491"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_sents_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = [sentence.split(' ') for sentence in words_joined_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dpe', 'the', 'job', 'well'], ['b', 'flax', 'd', 'be', 'a', 'regular', 'at', '-PRON-', 'house'], ['-PRON-', 'do', '-PRON-', 'job', 'simply', 'and', 'with', 'good', 'result'], ['-PRON-', 'be', 'reasonable', 'last', 'a', 'long', 'time', 'and', 'be', 'able', 'to', 'be', 'obtain', 'with', 'free', 'shipping', 'if', '-PRON-', 'hunt', 'around']]\n"
     ]
    }
   ],
   "source": [
    "print(unigram_sentences[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# The common_terms parameter add a way to give special treatment to common terms \n",
    "# (aka stop words) such that their presence between two words won’t prevent bigram detection. \n",
    "# It allows to detect expressions like “bank of america” or “eye of the beholder”.\n",
    "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "\n",
    "# Train a first-order phrase detector\n",
    "bigram_model = Phrases(unigram_sentences, threshold=0.5, scoring='npmi', common_terms=common_terms)\n",
    "\n",
    "# Transform unigram sentences into bigram sentences\n",
    "# Paired words are connected by an underscore, e.g. ice_cream\n",
    "bigram_sentences = []\n",
    "for sentence in unigram_sentences:\n",
    "    bigram_sentences.append(bigram_model[sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 42s, sys: 5.11 s, total: 3min 47s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train a second-order phrase detector\n",
    "# trigram_model = Phrases(bigram_sentences, min_count=5)\n",
    "trigram_model = Phrases(bigram_sentences, threshold=0.5, scoring='npmi', common_terms=common_terms)\n",
    "\n",
    "# Transform bigram sentences into trigram sentences\n",
    "trigram_sentences = []\n",
    "for sentence in bigram_sentences:\n",
    "    trigram_sentences.append(trigram_model[sentence])\n",
    "\n",
    "# remove any remaining stopwords\n",
    "trigram_sentences = [[word for word in sentence if word not in nlp.Defaults.stop_words] for sentence in trigram_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trigrams will be saved in a dataframe with a single column.\n",
    "# each row is one sentence from any review\n",
    "# each sentence is a single string separated by a single space.\n",
    "trigram_sentences_savedf = pd.DataFrame([u' '.join(sentence) for sentence in trigram_sentences], columns=['preprocessed_review'])\n",
    "save_df_s3(trigram_sentences_savedf, bucket_name, 'amazon_reviews/preprocessed_reviews.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_savedf = load_df_s3(bucket_name, 'amazon_reviews/preprocessed_reviews.feather', filetype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dpe job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b flax d regular -PRON- house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-PRON- -PRON- job simply good result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-PRON- reasonable long time able obtain free_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good product good price good result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 preprocessed_review\n",
       "0                                            dpe job\n",
       "1                      b flax d regular -PRON- house\n",
       "2               -PRON- -PRON- job simply good result\n",
       "3  -PRON- reasonable long time able obtain free_s...\n",
       "4                good product good price good result"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_sentences_savedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram_sentences = trigram_sentences_savedf.preprocessed_review.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605491"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(trigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_df = load_df_s3(bucket_name, 'amazon_reviews/unigram_sentences.feather', filetype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN DET NOUN ADV</td>\n",
       "      <td>dpe the job well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN NOUN NOUN VERB DET ADJ ADP ADJ NOUN</td>\n",
       "      <td>b flax d be a regular at -PRON- house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PRON VERB ADJ NOUN ADV CCONJ ADP ADJ NOUN</td>\n",
       "      <td>-PRON- do -PRON- job simply and with good result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PRON VERB ADJ VERB DET ADJ NOUN CCONJ VERB ADJ...</td>\n",
       "      <td>-PRON- be reasonable last a long time and be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ADJ NOUN ADJ NOUN ADJ NOUN</td>\n",
       "      <td>good product good price good result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number  sentence_number  \\\n",
       "0              1                1   \n",
       "1              1                2   \n",
       "2              1                3   \n",
       "3              1                4   \n",
       "4              1                5   \n",
       "\n",
       "                                         unigram_pos  \\\n",
       "0                                  NOUN DET NOUN ADV   \n",
       "1           NOUN NOUN NOUN VERB DET ADJ ADP ADJ NOUN   \n",
       "2          PRON VERB ADJ NOUN ADV CCONJ ADP ADJ NOUN   \n",
       "3  PRON VERB ADJ VERB DET ADJ NOUN CCONJ VERB ADJ...   \n",
       "4                         ADJ NOUN ADJ NOUN ADJ NOUN   \n",
       "\n",
       "                                   unigram_sentences  \n",
       "0                                   dpe the job well  \n",
       "1              b flax d be a regular at -PRON- house  \n",
       "2   -PRON- do -PRON- job simply and with good result  \n",
       "3  -PRON- be reasonable last a long time and be a...  \n",
       "4                good product good price good result  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3605491, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605491"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigram_sentences_savedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_df = pd.merge(unigram_sents_pos_df, trigram_sentences_savedf, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NOUN DET NOUN ADV</td>\n",
       "      <td>dpe the job well</td>\n",
       "      <td>dpe job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN NOUN NOUN VERB DET ADJ ADP ADJ NOUN</td>\n",
       "      <td>b flax d be a regular at -PRON- house</td>\n",
       "      <td>b flax d regular -PRON- house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PRON VERB ADJ NOUN ADV CCONJ ADP ADJ NOUN</td>\n",
       "      <td>-PRON- do -PRON- job simply and with good result</td>\n",
       "      <td>-PRON- -PRON- job simply good result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PRON VERB ADJ VERB DET ADJ NOUN CCONJ VERB ADJ...</td>\n",
       "      <td>-PRON- be reasonable last a long time and be a...</td>\n",
       "      <td>-PRON- reasonable long time able obtain free_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ADJ NOUN ADJ NOUN ADJ NOUN</td>\n",
       "      <td>good product good price good result</td>\n",
       "      <td>good product good price good result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number  sentence_number  \\\n",
       "0              1                1   \n",
       "1              1                2   \n",
       "2              1                3   \n",
       "3              1                4   \n",
       "4              1                5   \n",
       "\n",
       "                                         unigram_pos  \\\n",
       "0                                  NOUN DET NOUN ADV   \n",
       "1           NOUN NOUN NOUN VERB DET ADJ ADP ADJ NOUN   \n",
       "2          PRON VERB ADJ NOUN ADV CCONJ ADP ADJ NOUN   \n",
       "3  PRON VERB ADJ VERB DET ADJ NOUN CCONJ VERB ADJ...   \n",
       "4                         ADJ NOUN ADJ NOUN ADJ NOUN   \n",
       "\n",
       "                                   unigram_sentences  \\\n",
       "0                                   dpe the job well   \n",
       "1              b flax d be a regular at -PRON- house   \n",
       "2   -PRON- do -PRON- job simply and with good result   \n",
       "3  -PRON- be reasonable last a long time and be a...   \n",
       "4                good product good price good result   \n",
       "\n",
       "                                 preprocessed_review  \n",
       "0                                            dpe job  \n",
       "1                      b flax d regular -PRON- house  \n",
       "2               -PRON- -PRON- job simply good result  \n",
       "3  -PRON- reasonable long time able obtain free_s...  \n",
       "4                good product good price good result  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_s3(unigram_sents_pos_df, bucket_name, 'amazon_reviews/preprocessed_reviews.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram_sents_pos_df = load_df_s3(bucket_name, 'amazon_reviews/preprocessed_reviews.feather', filetype='feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>70</td>\n",
       "      <td>401</td>\n",
       "      <td>PRON VERB ADV VE...</td>\n",
       "      <td>-PRON- do not kn...</td>\n",
       "      <td>-PRON- do_not kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>70</td>\n",
       "      <td>402</td>\n",
       "      <td>PRON VERB ADJ AD...</td>\n",
       "      <td>-PRON- think -PR...</td>\n",
       "      <td>-PRON- think -PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>70</td>\n",
       "      <td>403</td>\n",
       "      <td>VERB ADV VERB DE...</td>\n",
       "      <td>do not recommend...</td>\n",
       "      <td>do_not recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>71</td>\n",
       "      <td>404</td>\n",
       "      <td>VERB PROPN NUM V...</td>\n",
       "      <td>mould motion 5 d...</td>\n",
       "      <td>mould_motion 5 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>71</td>\n",
       "      <td>405</td>\n",
       "      <td>PRON VERB ADV VE...</td>\n",
       "      <td>-PRON- do not sw...</td>\n",
       "      <td>-PRON- do_not sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>71</td>\n",
       "      <td>406</td>\n",
       "      <td>CCONJ PRON VERB ...</td>\n",
       "      <td>and i have -PRON...</td>\n",
       "      <td>-PRON- -PRON- sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>71</td>\n",
       "      <td>407</td>\n",
       "      <td>CCONJ ADP PRON A...</td>\n",
       "      <td>and besides -PRO...</td>\n",
       "      <td>-PRON- boil -PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>71</td>\n",
       "      <td>408</td>\n",
       "      <td>ADV ADV ADJ PART...</td>\n",
       "      <td>just too much to...</td>\n",
       "      <td>too_much wait ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>71</td>\n",
       "      <td>409</td>\n",
       "      <td>VERB ADV VERB</td>\n",
       "      <td>do not buy</td>\n",
       "      <td>do_not buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>72</td>\n",
       "      <td>410</td>\n",
       "      <td>VERB DET NOUN</td>\n",
       "      <td>be a gift</td>\n",
       "      <td>gift</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_number  sentence_number          unigram_pos    unigram_sentences  \\\n",
       "400             70              401  PRON VERB ADV VE...  -PRON- do not kn...   \n",
       "401             70              402  PRON VERB ADJ AD...  -PRON- think -PR...   \n",
       "402             70              403  VERB ADV VERB DE...  do not recommend...   \n",
       "403             71              404  VERB PROPN NUM V...  mould motion 5 d...   \n",
       "404             71              405  PRON VERB ADV VE...  -PRON- do not sw...   \n",
       "405             71              406  CCONJ PRON VERB ...  and i have -PRON...   \n",
       "406             71              407  CCONJ ADP PRON A...  and besides -PRO...   \n",
       "407             71              408  ADV ADV ADJ PART...  just too much to...   \n",
       "408             71              409        VERB ADV VERB           do not buy   \n",
       "409             72              410        VERB DET NOUN            be a gift   \n",
       "\n",
       "     preprocessed_review  \n",
       "400  -PRON- do_not kn...  \n",
       "401  -PRON- think -PR...  \n",
       "402  do_not recommend...  \n",
       "403  mould_motion 5 d...  \n",
       "404  -PRON- do_not sw...  \n",
       "405  -PRON- -PRON- sh...  \n",
       "406  -PRON- boil -PRO...  \n",
       "407  too_much wait ti...  \n",
       "408           do_not buy  \n",
       "409                 gift  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.iloc[400:410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_number          0\n",
       "sentence_number        0\n",
       "unigram_pos            0\n",
       "unigram_sentences      0\n",
       "preprocessed_review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_df.unigram_pos = unigram_sents_pos_df.unigram_pos.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-be0ce9e0e457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munigram_sents_pos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munigram_sents_pos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munigram_sents_pos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munigram_sents_pos_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/fastai/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, pat, n, expand)\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/fastai/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_split\u001b[0;34m(arr, pat, n)\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/fastai/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# should really _check_ for NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/fastai/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/fastai/lib/python3.6/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unigram_sents_pos_df.unigram_sentences = unigram_sents_pos_df.unigram_sentences.str.split(' ')\n",
    "unigram_sents_pos_df.preprocessed_review = unigram_sents_pos_df.preprocessed_review.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_df.iloc[400:410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make temp column with joined strings to enable easy detection of paired words\n",
    "unigram_sents_pos_df['temp'] = unigram_sents_pos_df.preprocessed_review.str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_number          0\n",
       "sentence_number        0\n",
       "unigram_pos            0\n",
       "unigram_sentences      0\n",
       "preprocessed_review    0\n",
       "temp                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOUN, DET, NOUN, ADV]</td>\n",
       "      <td>[dpe, the, job, well]</td>\n",
       "      <td>[dpe, job]</td>\n",
       "      <td>dpe job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[NOUN, NOUN, NOUN, VERB, DET, ADJ, ADP, ADJ, N...</td>\n",
       "      <td>[b, flax, d, be, a, regular, at, -PRON-, house]</td>\n",
       "      <td>[b, flax, d, regular, -PRON-, house]</td>\n",
       "      <td>b flax d regular -PRON- house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[PRON, VERB, ADJ, NOUN, ADV, CCONJ, ADP, ADJ, ...</td>\n",
       "      <td>[-PRON-, do, -PRON-, job, simply, and, with, g...</td>\n",
       "      <td>[-PRON-, -PRON-, job, simply, good, result]</td>\n",
       "      <td>-PRON- -PRON- job simply good result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[PRON, VERB, ADJ, VERB, DET, ADJ, NOUN, CCONJ,...</td>\n",
       "      <td>[-PRON-, be, reasonable, last, a, long, time, ...</td>\n",
       "      <td>[-PRON-, reasonable, long, time, able, obtain,...</td>\n",
       "      <td>-PRON- reasonable long time able obtain free_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[ADJ, NOUN, ADJ, NOUN, ADJ, NOUN]</td>\n",
       "      <td>[good, product, good, price, good, result]</td>\n",
       "      <td>[good, product, good, price, good, result]</td>\n",
       "      <td>good product good price good result</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number  sentence_number  \\\n",
       "0              1                1   \n",
       "1              1                2   \n",
       "2              1                3   \n",
       "3              1                4   \n",
       "4              1                5   \n",
       "\n",
       "                                         unigram_pos  \\\n",
       "0                             [NOUN, DET, NOUN, ADV]   \n",
       "1  [NOUN, NOUN, NOUN, VERB, DET, ADJ, ADP, ADJ, N...   \n",
       "2  [PRON, VERB, ADJ, NOUN, ADV, CCONJ, ADP, ADJ, ...   \n",
       "3  [PRON, VERB, ADJ, VERB, DET, ADJ, NOUN, CCONJ,...   \n",
       "4                  [ADJ, NOUN, ADJ, NOUN, ADJ, NOUN]   \n",
       "\n",
       "                                   unigram_sentences  \\\n",
       "0                              [dpe, the, job, well]   \n",
       "1    [b, flax, d, be, a, regular, at, -PRON-, house]   \n",
       "2  [-PRON-, do, -PRON-, job, simply, and, with, g...   \n",
       "3  [-PRON-, be, reasonable, last, a, long, time, ...   \n",
       "4         [good, product, good, price, good, result]   \n",
       "\n",
       "                                 preprocessed_review  \\\n",
       "0                                         [dpe, job]   \n",
       "1               [b, flax, d, regular, -PRON-, house]   \n",
       "2        [-PRON-, -PRON-, job, simply, good, result]   \n",
       "3  [-PRON-, reasonable, long, time, able, obtain,...   \n",
       "4         [good, product, good, price, good, result]   \n",
       "\n",
       "                                                temp  \n",
       "0                                            dpe job  \n",
       "1                      b flax d regular -PRON- house  \n",
       "2               -PRON- -PRON- job simply good result  \n",
       "3  -PRON- reasonable long time able obtain free_s...  \n",
       "4                good product good price good result  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_paired = unigram_sents_pos_df[unigram_sents_pos_df.temp.str.contains('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunal/anaconda2/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "unigram_sents_pos_df.drop(['temp'], axis=1, inplace=True)\n",
    "unigram_sents_pos_paired.drop(['temp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1647643, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_paired.shape    # 1,647,643 sentences with paired words out of 3,605,491 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3605491, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[PRON, VERB, ADJ, VERB, DET, ADJ, NOUN, CCONJ,...</td>\n",
       "      <td>[-PRON-, be, reasonable, last, a, long, time, ...</td>\n",
       "      <td>[-PRON-, reasonable, long, time, able, obtain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[ADJ, NOUN, ADJ, NOUN]</td>\n",
       "      <td>[fast, shipping, good, communication]</td>\n",
       "      <td>[fast_shipping, good, communication]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[DET, NOUN, VERB, NUM, NOUN, CCONJ, VERB, ADJ,...</td>\n",
       "      <td>[this, company, promise, 99, purity, and, have...</td>\n",
       "      <td>[company, promise, 99, purity, fast_shipping, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[PRON, VERB, ADV, VERB, ADP, DET, NOUN, ADP, N...</td>\n",
       "      <td>[-PRON-, can, not, comment, on, the, quality, ...</td>\n",
       "      <td>[-PRON-, can_not, comment, quality, product, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>[CCONJ, PRON, VERB, PART, VERB, ADJ]</td>\n",
       "      <td>[but, -PRON-, seem, to, be, legitimate]</td>\n",
       "      <td>[-PRON-, seem_to, legitimate]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_number  sentence_number  \\\n",
       "3               1                4   \n",
       "5               2                6   \n",
       "8               2                9   \n",
       "9               2               10   \n",
       "10              2               11   \n",
       "\n",
       "                                          unigram_pos  \\\n",
       "3   [PRON, VERB, ADJ, VERB, DET, ADJ, NOUN, CCONJ,...   \n",
       "5                              [ADJ, NOUN, ADJ, NOUN]   \n",
       "8   [DET, NOUN, VERB, NUM, NOUN, CCONJ, VERB, ADJ,...   \n",
       "9   [PRON, VERB, ADV, VERB, ADP, DET, NOUN, ADP, N...   \n",
       "10               [CCONJ, PRON, VERB, PART, VERB, ADJ]   \n",
       "\n",
       "                                    unigram_sentences  \\\n",
       "3   [-PRON-, be, reasonable, last, a, long, time, ...   \n",
       "5               [fast, shipping, good, communication]   \n",
       "8   [this, company, promise, 99, purity, and, have...   \n",
       "9   [-PRON-, can, not, comment, on, the, quality, ...   \n",
       "10            [but, -PRON-, seem, to, be, legitimate]   \n",
       "\n",
       "                                  preprocessed_review  \n",
       "3   [-PRON-, reasonable, long, time, able, obtain,...  \n",
       "5                [fast_shipping, good, communication]  \n",
       "8   [company, promise, 99, purity, fast_shipping, ...  \n",
       "9   [-PRON-, can_not, comment, quality, product, -...  \n",
       "10                      [-PRON-, seem_to, legitimate]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_paired.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunal/anaconda2/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "unigram_sents_pos_paired['has_paired'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an arbitrary sentence and it's transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>has_paired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[PRON, VERB, ADJ...</td>\n",
       "      <td>[-PRON-, be, rea...</td>\n",
       "      <td>[-PRON-, reasona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[ADJ, NOUN, ADJ,...</td>\n",
       "      <td>[fast, shipping,...</td>\n",
       "      <td>[fast_shipping, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[DET, NOUN, VERB...</td>\n",
       "      <td>[this, company, ...</td>\n",
       "      <td>[company, promis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[PRON, VERB, ADV...</td>\n",
       "      <td>[-PRON-, can, no...</td>\n",
       "      <td>[-PRON-, can_not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>[CCONJ, PRON, VE...</td>\n",
       "      <td>[but, -PRON-, se...</td>\n",
       "      <td>[-PRON-, seem_to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_number  sentence_number          unigram_pos    unigram_sentences  \\\n",
       "3               1                4  [PRON, VERB, ADJ...  [-PRON-, be, rea...   \n",
       "5               2                6  [ADJ, NOUN, ADJ,...  [fast, shipping,...   \n",
       "8               2                9  [DET, NOUN, VERB...  [this, company, ...   \n",
       "9               2               10  [PRON, VERB, ADV...  [-PRON-, can, no...   \n",
       "10              2               11  [CCONJ, PRON, VE...  [but, -PRON-, se...   \n",
       "\n",
       "    preprocessed_review  has_paired  \n",
       "3   [-PRON-, reasona...           1  \n",
       "5   [fast_shipping, ...           1  \n",
       "8   [company, promis...           1  \n",
       "9   [-PRON-, can_not...           1  \n",
       "10  [-PRON-, seem_to...           1  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_paired.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>unigram_pos</th>\n",
       "      <th>unigram_sentences</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>has_paired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOUN, DET, NOUN...</td>\n",
       "      <td>[dpe, the, job, ...</td>\n",
       "      <td>[dpe, job]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[NOUN, NOUN, NOU...</td>\n",
       "      <td>[b, flax, d, be,...</td>\n",
       "      <td>[b, flax, d, reg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[PRON, VERB, ADJ...</td>\n",
       "      <td>[-PRON-, do, -PR...</td>\n",
       "      <td>[-PRON-, -PRON-,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[PRON, VERB, ADJ...</td>\n",
       "      <td>[-PRON-, be, rea...</td>\n",
       "      <td>[-PRON-, reasona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[ADJ, NOUN, ADJ,...</td>\n",
       "      <td>[good, product, ...</td>\n",
       "      <td>[good, product, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number  sentence_number          unigram_pos    unigram_sentences  \\\n",
       "0              1                1  [NOUN, DET, NOUN...  [dpe, the, job, ...   \n",
       "1              1                2  [NOUN, NOUN, NOU...  [b, flax, d, be,...   \n",
       "2              1                3  [PRON, VERB, ADJ...  [-PRON-, do, -PR...   \n",
       "3              1                4  [PRON, VERB, ADJ...  [-PRON-, be, rea...   \n",
       "4              1                5  [ADJ, NOUN, ADJ,...  [good, product, ...   \n",
       "\n",
       "   preprocessed_review  has_paired  \n",
       "0           [dpe, job]           0  \n",
       "1  [b, flax, d, reg...           0  \n",
       "2  [-PRON-, -PRON-,...           0  \n",
       "3  [-PRON-, reasona...           0  \n",
       "4  [good, product, ...           0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_sents_pos_df['has_paired'] = 0\n",
    "unigram_sents_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunal/anaconda2/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "unigram_sents_pos_df[unigram_sents_pos_df.temp.str.contains('_')]['has_paired'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liver', 'support', 'supports', 'liver', 'function', 'stimulate', 'des', 'intoxication', 'and', 'restore', 'liver', 'function', 'eliminate', 'harmful', 'metabolite']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_sents_pos_paired.unigram_sentences.iloc[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PROPN', 'PROPN', 'NOUN', 'NOUN', 'VERB', 'X', 'NOUN', 'CCONJ', 'VERB', 'NOUN', 'NOUN', 'VERB', 'ADJ', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_sents_pos_paired.unigram_pos.iloc[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liver', 'support', 'supports', 'liver_function', 'stimulate_des_intoxication_and_restore', 'liver_function', 'eliminate', 'harmful', 'metabolite']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_sents_pos_paired.preprocessed_review.iloc[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Liver Support\" Supports liver function, stimulates des-intoxication and restores liver functions, eliminates harmful metabolites'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText.iloc[13].split('.')[1]    # corresponding full text review sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sents_pos_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3605491"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43362695"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size with unigrams\n",
    "len([word for sentence in unigram_sentences for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21960569"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size with trigrams\n",
    "len([word for sentence in trigram_sentences for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_flat = [word for sentence in trigram_sentences for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21960569"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigrams_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dpe', 'job', 'b', 'flax', 'd', 'regular', '-PRON-', 'house', '-PRON-', '-PRON-', 'job', 'simply', 'good', 'result', '-PRON-']\n"
     ]
    }
   ],
   "source": [
    "print(trigrams_flat[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_words = set([word for word in trigrams_flat if '_' in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203277"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paired_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mouth', 'quickly', 'lozenge', 'formula', 'dissolve', 'slowly', 'preferable', 'accord', '-PRON-', 'research', 'this_product', 'great', 'side_effect', '-PRON-', '-PRON-', 'cold', 'sore_throat', 'soon', 'start', '-PRON-', 'every_day', '-PRON-', 'start', 'come', 'cold', '-PRON-', 'usual', 'symptom', 'anticipate', 'sick', 'day', '-PRON-', 'usual', 'pattern', '-PRON-', 'sick', 'anticipate', 'taking', 'this_product', 'reason', '-PRON-', 'come', '-PRON-', 'cold', 'sore_throat', '-PRON-', 'great', '-PRON-', 'recommend', 'this_product']\n"
     ]
    }
   ],
   "source": [
    "print(trigrams_flat[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "night.not_a_miracle_cure\n",
      "pinot_noir\n",
      "solublenot_certify_kosher_or_halal$8.99\n",
      "count)*****fat_solublenot_certify_kosher\n",
      "240_softgels)****fat_solublenot_certify\n",
      "solublenot_certify_kosher_or_halal$13.78\n",
      "8220;not_hungry&#8221\n",
      "distilledmercury_freenot_enteric_coatednot\n",
      "cholesterolmolecularly_distilledmercury_freenot_enteric\n",
      "estafa!not_worth_the_money\n",
      "34;not_guilty&#34\n",
      "hacking_snot_fill\n",
      "solublenot_certify_kosher_or_halal$27.99\n",
      "each)****triglycerides_formnot_certify_kosher\n",
      "freshness_34;not_rancid&#34\n",
      "formnot_certify_kosher_or_halal$45.82\n",
      "formnot_certify_kosher_or_halal$45.46\n",
      "hungry.not_a_stimulant\n",
      "240_softgels,)fat_solublenot_certify\n",
      "stearateschelatedvegetariannot_enteric_coatedcontain_laxative\n",
      "34;not_work&#34;.\n",
      "enteric_coatednot_vegetarianone\n",
      "supply).)ethyl_ester_formnot_certify\n",
      "22.8=_78.6not_373i_freak\n",
      "cholesterolmolecularly_distilledno_mercurynot_enteric\n",
      "solublenot_certify_kosher_or_halal$27.77\n",
      "90-count)*****ubiquinolfat_solublenot_certify_kosher\n",
      "mercurynot_enteric_coatednot_vegetarianphospholipid\n",
      "120_softgels)*****not_certify_kosher\n",
      "90_count)*****not_certify\n",
      "stearateschelatedvegetariannot_enteric_coatedpossibly_contain\n",
      "dontnot_purches\n",
      "supplement!not_surprisingly_pharmaceutical\n",
      "starchy_substances(not_dilute\n",
      "formnot_certify_kosher_or_halal$16.49\n",
      "soycontains_gmoscontain_cholesterolnot_vegetariannot\n",
      "34;not_addictive&#34;--lie\n",
      "coatednot_vegetarian?ifos_rating_=\n",
      "coatednot_vegetarianphospholipid_=\n",
      "solublenot_certify_kosher_or_halal$10.94\n",
      "magnesium_glycinatewater_solublenot_certify\n",
      "solublenot_certify_kosher_or_halal$15.18\n",
      "solublenot_certify_kosher_or_halal$25.87\n",
      "formnot_certify_kosher_or_halal$10.99\n",
      "solublenot_certify_kosher_or_halal$37.85\n",
      "tauratewater_solublenot_certify_kosher\n",
      "regularly(not_excessive\n",
      "coatednot_vegetarianvitamin_d3\n",
      "glass_of_pinot_grigio\n",
      "softgels)*****fat_solublenot_certify_kosher\n",
      "solublenot_certify_kosher_or_halal$25.99\n",
      "day(not_jittery\n",
      "formnot_certify_kosher_or_halal$39.95\n",
      "sonot_happy-\n",
      "mercurynot_enteric_coatednot_vegetarianikos\n",
      "handle_stress(not_a_cure\n",
      "cholesterolno_mercurymolecularly_distillednot_vegetarianifos\n",
      "softgels)not_certify_kosher_or_halal$25.49\n",
      "day(not_the_nervous\n",
      "34;not_great&#34;.\n",
      "distillednot_enteric_coatednot_vegetarianifos\n",
      "vcaps)*****fat_solublenot_certify_kosher\n",
      "solublenot_certify_kosher_or_halal$25.15\n",
      "solublenot_certify_kosher_or_halal$14.98\n",
      "solublenot_certify_kosher_or_halal$22.95\n",
      "solublenot_certify_kosher_or_halal$29.29\n",
      "22_knot_gust\n",
      "isolate(not_concentrate\n",
      "enteric_coatednot_vegetarianphone_number\n",
      "lol!!!)-not_yet!!!.\n",
      "softgel)triglycerides_formnot_certify_kosher\n",
      "concoctions!not_particularly_worried\n",
      "solublenot_certify_kosher_or_halal$37.99\n",
      "low_carb_diet\".not_necessarily\n",
      "400-count_softgels)triglyceride_formnot_certify\n",
      "34;not_right&#34\n",
      "dead_fisn!not_worth_the_money\n",
      "count)****ubiquinolfat_solublenot_certify_kosher\n",
      "solublenot_certify_kosher_or_halal$13.80\n",
      "formnot_certify_kosher_or_halal$44.45\n",
      "sgels)****ubiquinolwater_solublenot_certify_kosher\n",
      "pill(not_raspberry).i\n",
      "unconfirmednot_enteric_coatednot_vegetarianifos\n",
      "isnot_a_gimmick\n",
      "gel_caps)not_certify\n",
      "solublenot_certify_kosher_or_halal$31.94\n",
      "couldnot_afford\n",
      "acnnot_speak\n",
      "formnot_certify_kosher_or_halal$30.12\n",
      "amazon(not_3rd_party\n",
      "knot_tension_spacing\n",
      "60_count)****not_certify\n",
      "distilledno_mercurynot_enteric_coatednot\n",
      "crucial_andnot_user_friendly\n",
      "34;not_normal.&#34\n",
      "300_softgels)fat_solublenot_certify\n",
      "formnot_certify_kosher_or_halal$19.12\n",
      "formnot_certify_kosher_or_halal$44.95\n",
      "solublenot_certify_kosher_or_halal$11.22\n",
      "34;not_much&#34\n",
      "formnot_certified_kosher_or_halal$11.97\n",
      "tests(not_serotonin\n",
      "34;not_trying&#34\n",
      "proprietary_information)enteric_coatednot_vegetarianifos\n",
      "solublenot_certify_kosher_or_halal$11.85\n",
      "mercurymolecularly_distilledenteric_coatednot_vegetarianifos\n",
      "chelatewater_solublenot_certify_kosher\n",
      "flowersnot_intend\n",
      "count)not_certify_kosher_or_halal$25.19\n",
      "softgel)ubiquinolfat_solublenot_certify_kosher\n",
      "magnesium_citratewater_solublenot_certify\n",
      "gmoscontain_cholesterolmercury_freenot_enteric\n",
      "frustrating!not_anymore\n",
      "label(not_a_sticker).belive\n",
      "count)ubiquinolfat_solublenot_certify_kosher\n",
      "middle_of_the_day(not_unusual\n",
      "say:\"not_intend\n",
      "solublenot_certify_kosher_or_halal$9.14\n",
      "capsules)not_certify_kosher_or_halal$10.79\n",
      "solublenot_certify_kosher_or_halal$23.66\n",
      "mercurynot_enteric_coatednot_vegetarianone\n",
      "180_softgels)*****triglyceride_formnot_certify\n",
      "eating,[not_starve\n",
      "it(not_necessarily\n",
      "vegetariannot_enteric\n",
      "unot_+_20:00\n",
      "120_softgels)*****ubiquinolfat_solublenot_certify\n",
      "bat-----not_noticing\n",
      "formnot_certify_kosher_or_halal$13.99\n",
      "solublenot_certify_kosher_or_halal$13.59\n",
      "it&#8230;not_pleasant\n",
      "magnesium_oxidewater_solublenot_certify\n",
      "gprotein_21_gnot_a_significant\n",
      "powdered_ionic)vegetariannot_enteric_coatedpossibly\n",
      "glycinatefat_solublenot_certify_kosher\n",
      "34;apart.&#34;not_melted_goo\n",
      "60-v_gel_bottle)not_certify\n",
      "soft_gel_60-count)not_certify\n",
      "cholesterolflash_distillationnot_enteric_coatednot\n",
      "co2_technologyenteric_coatednot_vegetarianifos\n",
      "solublenot_certify_kosher_or_halal$11.05\n",
      "34;not_tasty&#34\n",
      "technologyenteric_coatednot_vegetarianifos_rating\n",
      "soyno_gmosno_cholesterolchelatednot_vegetariannot\n",
      "cholesterolno_mercurymolecularly_distillednot_enteric\n",
      "formnot_certify_kosher_or_halal$11.59\n",
      "reviews?cannot_honestly\n",
      "freemolecularly_distilledmercury_freenot_enteric\n",
      "360_softgels)*****fat_solublenot_certify\n",
      "solublenot_certify_kosher_or_halal$31.50\n",
      "34;not_helpful&#34_vote\n",
      "formnot_certify_kosher_or_halal$37.52\n",
      "solublenot_certify_kosher_or_halal$17.86\n",
      "including(not_limit\n",
      "nonot_certify_kosher_or_halal$38.25\n",
      "consistent_with_the_directions,(not_miraculously_tho)it\n",
      "she_cannnot_suck\n",
      "xtra_60ct)triglycerides_formnot_certify\n",
      "carnauba_waxnot_exactly\n",
      "gelatinmisleadingnot_goodnot_vegetarianyeahuh_hu\n",
      "solublenot_certify_kosher_or_halal$\n",
      "enteric_coatednot_vegetariansource_of_astaxanthin\n",
      "enteric_coatednot_vegetarianone_100\n",
      "softgels)***ubiquinonenot_certify_kosher_or_halal$24.33\n",
      "solublenot_certify_kosher_or_halal$11.74\n",
      "guarantee!)****ethyl_ester_formnot_certify\n",
      "34;not_responding&#34\n",
      "300_softgels)****fat_solublenot_certify\n",
      "daynot_dailyyou\n",
      "240_softgels)fat_solublenot_certify\n",
      "solublenot_certify_kosher_or_halal$17.09\n",
      "ki_cannot_doknow\n",
      "solublenot_certify_kosher_or_halal$14.99\n",
      "34;not_hungry&#34;.\n",
      "freenot_enteric_coatednot_vegetarianifos\n",
      "formnot_certify_kosher_or_halal$44.70\n",
      "soft_gel_60-count)*****not_certify\n",
      "rugbynot_coat\n",
      "freeenteric_coatednot_vegetarianphospholipid_=\n",
      "cholesterolno_mercurynot_enteric_coatednot\n",
      "soyno_gmosno_cholesterolvegetariannot_enteric\n",
      "antioxidant))not_certify_kosher_or_halalfat\n",
      "solublenot_certify_kosher_or_halal$13.97\n",
      "solublenot_certify_kosher_or_halal$7.36\n",
      "formnot_certify_kosher_or_halal$23.07\n",
      "coatednot_vegetarianone_100_mg\n",
      "solublenot_certify_kosher_or_halal$11.45\n",
      "4:30_5:00.not_fully\n",
      "150_softgel)*****ubiquinolfat_solublenot_certify\n",
      "herbalife_products.not_impressed\n",
      "japanese_knot_weed\n",
      "vegetariannot_enteric_coatedphone_number\n",
      "re_order--------not_likely\n",
      "drynot_a_fan\n",
      "great.not_gritty\n",
      "180ct)****triglyceride_formnot_certify_kosher\n",
      "stick\".not_forgetting\n",
      "peanuts(not_crush_nut\n",
      "mercurycontain_cholesterolmolecularly_distillednot_vegetarianifos\n",
      "freenot_enteric_coatednot_vegetarianphospholipid\n",
      "appetite*not_good!.\n",
      "orange_juice(not_consentrate\n",
      "ester_formnot_certify_kosher\n",
      "yesnot_certify_kosher_or_halal$260.00\n",
      "formprescription_require_nonot_certified\n",
      "softgels)ubiquinonefat_solublenot_certify_kosher\n",
      "solublenot_certify_kosher_or_halal$32.94\n",
      "solublenot_certify_kosher_or_halal$37.65\n",
      "chelatedvegetariannot_enteric_coatedphone_number\n",
      "softgel)****ubiquinolfat_solublenot_certify_kosher\n",
      "120_softgels)ubiquinolfat_solublenot_certify\n",
      "formnot_certify_kosher_or_halal$50.64\n",
      "240_softgels,)*****fat_solublenot_certify\n",
      "krill_oil_with_astaxanthin)not_certify\n",
      "thyroid_biospies(not_cancer\n",
      "trader_tom(not_trader_joe)are\n",
      "formnot_certify_kosher_or_halal$23.99\n",
      "solublenot_certify_kosher_or_halal$27.56\n",
      "super_antioxidant))*****not_certify_kosher\n",
      "legs(not_itchy\n",
      "reasonable_price!not_a_substitute\n",
      "solublenot_certify_kosher_or_halal$24.75\n",
      "solublenot_certify_kosher_or_halal$15.41\n",
      "solublenot_certify_kosher_or_halal$18.49\n",
      "snot_a_stranger\n",
      "60_capliques)not_certify_kosher\n",
      "tried.not_nasty\n",
      "distillationnot_enteric_coatednot_vegetarianifos\n",
      "energy.not_jittery\n",
      "34;not_farm_raise\n",
      "unconfirmed)not_certified_kosher_or_halal$23.99\n",
      "yesnot_certify_kosher_or_halal$210.00\n",
      "solublenot_certify_kosher_or_halal$15.69\n",
      "chelatedvegetariannot_enteric_coatedcontain_laxative\n",
      "ia_mnot_discourage\n",
      "mercurymolecularly_distillednot_enteric_coatednot\n",
      "pucker_balloon_knot_erupt\n",
      "flora)****triglycerides_formnot_certify_kosher\n",
      "beauty])fat_solublenot_certify_kosher\n",
      "formnot_certify_kosher_or_halal$46.95\n",
      "scary_friendliernot_a_beast\n",
      "mint-(not_papaya),helps\n",
      "formnot_certify_kosher_or_halal$21.99\n",
      "solublenot_certify_kosher_or_halal$9.49\n",
      "again!not_worth_the_money\n",
      "solublenot_certify_kosher_or_halal$20.23\n",
      "formnot_certify_kosher_or_halal$69.95\n",
      "solublenot_certify_kosher_or_halal$17.50\n",
      "enteric_coatednot_vegetarianifos_rating\n",
      "beauty])****fat_solublenot_certify_kosher\n",
      "formnot_certify_kosher_or_halal$45.25\n",
      "vote_34;not_helpful&#34\n",
      "less.[not_affiliate\n",
      "formnot_certified_koshercertified_halal$18.97\n",
      "2,not_drastic_wt\n",
      "formnot_certify_kosher_or_halal$44.75\n",
      "molecularly_distillednot_enteric\n",
      "b3_--not_the_impostor_inositol--\n",
      "soycontains_gmoscholesterol_freenot_vegetariannot\n",
      "solublenot_certify_kosher_or_halal$22.00\n",
      "will!?!not_true\n",
      "180-count)***triglycerides_formnot_certify_kosher\n",
      "softgels)not_certify_kosher_or_halal$22.45\n",
      "best.doesnot_rise\n",
      "formnot_certify_kosher_or_halal$29.65\n",
      "taste)-not_silver_ion\n",
      "immediately.not_irritate\n",
      "freemercury_freenot_enteric_coatednot\n",
      "12mg)not_certify_kosher_or_halalfat\n",
      "alpha_lipoic_acidnot_a_dangerous\n",
      "nnnnnnot_gggggood\n",
      "softgels)fat_solublenot_certify_kosher\n",
      "-not_that!.\n",
      "easily*not_overly_bitter\n",
      "3/19/13not_a_sniffle!i\n",
      "mercuryenteric_coatednot_vegetarianphospholipid_=\n",
      "form!\"not_correct\n",
      "30-count)****ethyl_ester_formnot_certify\n",
      "ubiquinol_coq10)ubiquinolfat_solublenot_certify\n",
      "solublenot_certify_kosher_or_halal$58.40\n",
      "digestnot_a_giant_horse_pillno\n",
      "solublenot_certify_kosher_or_halal$20.22\n",
      "stearatesnot_chelatedvegetariannot_enteric_coatedcompany\n",
      "enteric_coatednot_vegetarianvitamin_d3\n",
      "cholesterolnot_vegetariannot_enteric_coatedphone\n",
      "caps)*****not_certify_kosher_or_halalfat\n",
      "b9-(not_synthetic\n",
      "300.not_ony\n",
      "solublenot_certify_kosher_or_halal$24.99\n",
      "solublenot_certify_kosher_or_halal$24.00\n",
      "either.'not_a_fan\n",
      "citric_acidnot_chelatedvegetariannot_enteric\n",
      "softgels)not_certify_kosher_or_halal$28.95\n",
      "formnot_certify_kosher_or_halal$31.49\n",
      "coatednot_vegetarianifos_rating_=\n",
      "solublenot_certify_kosher_or_halal$6.75\n",
      "solublenot_certify_kosher_or_halal$12.19\n",
      "solublenot_certify_kosher_or_halal$39.30\n",
      "34;not_enough&#34\n",
      "time?not_likely\n",
      "salty_and_bitter(not_fond\n",
      "coq10)ubiquinolfat_solublenot_certify_kosher\n",
      "solublenot_certify_kosher_or_halal$49.49\n",
      "softgels)ubiquinonenot_certify_kosher_or_halal$20.49\n",
      "my_pants.didnot_slip_down.maintained\n",
      "gmosno_cholesterolcontain_stearateschelatedvegetariannot_enteric\n",
      "softgels)not_certify_kosher_or_halalfat\n",
      "34;not_delicious&#34_range\n",
      "gmosno_cholesterolno_mercurynot_enteric\n",
      "oxidefat_solublenot_certify_kosher\n",
      "earlier!not_impressed\n",
      "softgels)not_certify_kosher_or_halal$26.09\n",
      "180-count)***triglyceride_formnot_certify_kosher\n",
      "that.not_purchased\n",
      "freenot_enteric_coatednot_vegetarianone\n",
      "btw.)not_exactly\n",
      "chelatedvegetariannot_enteric_coatedcompany_number\n",
      "softgels)***ethyl_ester_formnot_certify\n",
      "flora)triglyceride_formnot_certify_kosher\n",
      "breathing,(not_a_pulmonary\n",
      "60-count)****ubiquinolfat_solublenot_certify_kosher\n",
      "sodiumnot_the_nutritional_powerhouse\n",
      "cannot_hold_a_candle\n",
      "nnot_agree\n",
      "60-v_gel_bottle)*****not_certify\n",
      "frustration(not_smart\n",
      "us.not_entirely\n",
      "kid.&#34;not_sleeping,&#34\n",
      "solublenot_certify_kosher_or_halal$24.95\n",
      "formprescription_require_nonot_certify\n",
      "soyno_gmoscontain_cholesterolnot_vegetariannot\n",
      "34;not_valid\n",
      "veggie_based.not_derive_from\n",
      "to/_not_und\n",
      "testingnot_surebut\n",
      "snot_nosed\n",
      "couldnot_guarantee\n",
      "solublenot_certify_kosher_or_halal$6.99\n",
      "180-count)ethyl_ester_formnot_certify\n",
      "coatednot_vegetarianone_300_mg\n",
      "formnot_certify_kosher_or_halal$24.95\n",
      "chelatednot_vegetariannot_enteric_coatedcontain\n",
      "doe_snot_interfere\n",
      "softgels_60-count)****ubiquinolfat_solublenot_certify\n",
      "bottle)ubiquinonenot_certify_kosher_or_halal$13.49\n",
      "30-count)ethyl_ester_formnot_certify\n",
      "solublenot_certify_kosher_or_halal$15.50\n",
      "stearate)chelatednot_vegetariannot_enteric_coatedno\n",
      "formnot_certified_koshercertified_halal$17.53\n",
      "34;not_cool&#34\n",
      "soyno_gmosno_cholesterolnot_vegetariannot\n",
      "dietary_life!--not_dramatically\n",
      "solublenot_certify_kosher_or_halal$19.19\n",
      "impurities.(not_distilled)when\n",
      "slightly_sweet.not_exactly\n",
      "eczema(not_apply_directly\n",
      "softgels)*****ethyl_esters_formnot_certify\n",
      "90_softgels)****triglyceride_formnot_certify\n",
      "tart\"-\"citrusy\"-\"not_unpleasant\n",
      "formnot_certify_kosher_or_halal$37.10\n",
      "mercurymolecularly_distillednot_vegetarianifos_rating\n",
      "dgl_licorice.[not_affiliate\n",
      "solublenot_certify_kosher_or_halal$24.57\n",
      "solublenot_certify_kosher_or_halal$23.04\n",
      "unconfirmed)not_enteric_coatednot_vegetarianifos\n",
      "distilledenteric_coatednot_vegetarianifos_rating\n",
      "34;not_hungry&#34\n",
      "softgels)ethyl_ester_formnot_certified\n",
      "esters_formnot_certify_kosher\n",
      "bisglycinatewater_solublenot_certify_kosher\n",
      "xtra_60ct)triglycerides_form****not_certify\n",
      "softgels)ubiquinonenot_certify_kosher_or_halal$24.47\n",
      "solublenot_certify_kosher_or_halal$6.57\n",
      "solublenot_certify_kosher_or_halal$28.39\n",
      "chelatednot_vegetariannot_enteric_coatedphone\n",
      "monot_boostercould\n",
      "donnot_buy!.\n",
      "softgels)not_certify_kosher_or_halal$25.98\n",
      "chelatedvegetariannot_enteric_coatedpossibly_contain\n",
      "products!you_cannot_beat\n",
      "formnot_certify_kosher_or_halal$19.40\n",
      "beauty])*****fat_solublenot_certify_kosher\n",
      "cannot_hurt!.\n",
      "vegetariannot_enteric_coatedpossibly_contain\n",
      "swamp_snot_mixture\n",
      "34;not_bad&#34\n",
      "enteric_coatednot_vegetarianphospholipid_=\n",
      "supply))****ubiquinonefat_solublenot_certify_kosher\n",
      "weightnot_a_magic\n",
      "sgels)***not_certify_kosher_or_halal$45.74\n",
      "crackpot_or_outright_nutters).not_withstand\n",
      "oz.))*****ethyl_ester_formnot_certify\n",
      "digestion.a_must.not_habit\n",
      "34;not_myself&#34\n",
      "pressednot_enteric_coatedvegetarianifos_rating\n",
      "60_capliques)****not_certify_kosher\n",
      "buy;*tiny*butterfinger_tasting*not_the_healthiest\n",
      "30_softgels)****not_certify\n",
      "formnot_certify_kosher_or_halal$22.23\n",
      "30_capsules)***not_certify\n",
      "freenot_enteric_coatedvegetarianifos_rating\n",
      "100,not_the_kyolic\n",
      "solublenot_certify_kosher_or_halal$32.99\n",
      "90_count)****not_certify_kosher\n",
      "formnot_certify_kosher_or_halal$38.15\n",
      "formnot_certify_kosher_or_halal$19.47\n",
      "serving)*****not_certify_kosher_or_halalfat\n",
      "softgels)not_certify_kosher_or_halal$29.21\n",
      "solublenot_certify_kosher_or_halal$14.48\n",
      "count)not_certify_kosher_or_halalfat\n",
      "snot_rocket\n",
      "folic_acid_4%-not_zero\n",
      "negligable_andnot_acceptable\n",
      "capsules_60-count)*****fat_solublenot_certify\n",
      "xtra_8oz)*****triglycerides_formnot_certify\n",
      "formnot_certify_kosher_or_halal$44.59\n",
      "loo_weightnot_workingnot\n",
      "is!(not_a_shot_of_course)i\n",
      "formnot_certify_kosher_or_halal$42.95\n"
     ]
    }
   ],
   "source": [
    "# print trigrams containing 'no' or 'not'\n",
    "for w in paired_words:\n",
    "    if ('_no_' in w or 'not_' in w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_text = unigram_sentences_savedf.unigram_sentences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"magnesium malate magnesium glycinatewater solublenot certify kosher or halal$ n a for 120 200 mg capsule on amazonrecommended serving two capsulesprice per gel cap $ n a use amazon 's price)price per 100 mgs magnesium $ n a use amazon 's price)no soyno gmosno cholesterolno stearateschelatedvegetariannot enteric coatedno laxative propertiesno ingredient source from chinaphone number 800 476 3542manufactur in the u.s.a.ingredient magnesium malate chelate magnesium glycinate and vegetarian capsule non gmo plant cellulose)doctor 's good high absorption 100 chelated magnesium\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for one of the weird paired terms in the list above: 'solublenot_certify_kosher'\n",
    "# this shows the review it was a part of before getting paired\n",
    "[sent for sent in unigram_text if 'not certify kosher' in sent][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly, there was a problem in the unigram terms as well since `soluble` and `not` are joined together (along with other words).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"KAL Magnesium Glycinate 400 vs Nine Leading Magnesium Supplements. ***Here is a side-by-side comparison of ten leading magnesium supplements: Nutrigold Magnesium Gold, Doctor's Best High Absorption 100% Chelated Magnesium, JigSaw Magnesium w/SRT, Now Foods Magnesium Citrate (200 mgs), Now Foods Magnesium Capsules (400 mgs), Solgar Magnesium Citrate, Life Extension Magnesium Caps, Thorne Research Magnesium Citrate, Bluebonnet Nutrition Albion Chelated Magnesium, and KAL Magnesium Glycinate 400.Magnesium is needed for more than 300 biochemical reactions in the body. It helps maintain normal muscle and nerve function, keeps heart rhythm steady, supports a healthy immune system, and keeps bones strong. Magnesium also helps regulate blood sugar levels, promotes normal blood pressure, and is known to be involved in energy metabolism and protein synthesis. There is an increased interest in the role of magnesium in preventing and managing disorders such as hypertension, cardiovascular disease, and diabetes.Magnesium is present in all cells of the body. It is a mineral that is critical for energy production and metabolism, muscle contraction, nerve impulse transmission, and bone mineralization. It helps to regulate calcium transport and absorption. By stimulating the secretion of calcitonin, it aids the influx of calcium into bone and promotes optimal bone mineralization. It has been called nature's calcium channel blocker. The idea refers to magnesium's ability to block calcium from entering muscle and heart cells.BREAKDOWN: Here is a breakdown of these supplements.Nutrigold Magnesium Gold (See,Nutrigold Magnesium Gold 120 Vegetarian Capsules)*****Form: magnesium malate / magnesium glycinateWater solubleNot certified Kosher or Halal$ N/A for 120 200 mg capsules on AmazonRecommended Serving: two capsulesPrice per gel cap: $ N/A (using Amazon's price)Price per 100 mgs magnesium: $ N/A (using Amazon's price)No soyNo GMOsNo cholesterolNo stearatesChelatedVegetarianNot enteric c\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the same review in the original unprocessed reviews dataset\n",
    "[sent for sent in text if '$17.09' in sent][0][:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the unprocessed reviews as well, `soluble` and `not` are joined together (along with other words).  This is a problem with the data itself; not an outcome of the preprocessing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = reviews[reviews.asin.str.contains('B00013YZ1Q')]\n",
    "q2 = q1[q1.summary.str.contains('KAL Magnesium Glycinate 400 vs Nine Leading Magnesium')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KAL Magnesium Glycinate 400 vs Nine Leading Magnesium Supplements'], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the product from the review above:\n",
    "q2.summary.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('do_not', 268437),\n",
       " ('this_product', 207554),\n",
       " ('seem_to', 45681),\n",
       " ('can_not', 45528),\n",
       " ('great_product', 41158),\n",
       " ('weight_loss', 35438),\n",
       " ('so_far', 29550),\n",
       " ('at_all', 25321),\n",
       " ('this_stuff', 23679),\n",
       " ('highly_recommend', 23157),\n",
       " ('lose_weight', 23118),\n",
       " ('fish_oil', 21909),\n",
       " ('side_effect', 17800),\n",
       " ('as_well', 17148),\n",
       " ('would_recommend', 16050),\n",
       " ('in_the_morning', 15725),\n",
       " ('at_least', 14776),\n",
       " ('will_continue', 14454),\n",
       " ('more_than', 13908),\n",
       " ('more_energy', 13045),\n",
       " ('per_day', 11691),\n",
       " ('every_day', 11147),\n",
       " ('garcinia_cambogia', 10203),\n",
       " ('as_well_as', 9379),\n",
       " ('at_night', 8951),\n",
       " ('very_happy', 8328),\n",
       " ('too_much', 8297),\n",
       " ('year_ago', 8001),\n",
       " ('no_side_effect', 7872),\n",
       " ('high_quality', 7664),\n",
       " ('energy_level', 7583),\n",
       " ('vitamin_d', 7473),\n",
       " ('vitamin_c', 7400),\n",
       " ('year_old', 7201),\n",
       " ('run_out', 7056),\n",
       " ('no_longer', 7043),\n",
       " ('five_star', 6781),\n",
       " ('suffer_from', 6679),\n",
       " ('dr._oz', 6578),\n",
       " ('wake_up', 6439),\n",
       " ('immune_system', 6167),\n",
       " ('twice_a_day', 6086),\n",
       " ('on_the_market', 6069),\n",
       " ('customer_service', 6019),\n",
       " ('even_though', 5759),\n",
       " ('less_than', 5695),\n",
       " ('omega_3', 5605),\n",
       " ('krill_oil', 5506),\n",
       " ('blood_pressure', 5494),\n",
       " ('as_direct', 5476),\n",
       " ('very_pleased', 5396),\n",
       " ('anyone_who', 5368),\n",
       " ('5_star', 5212),\n",
       " ('waste_of_money', 5048),\n",
       " ('go_away', 4994),\n",
       " ('end_up', 4937),\n",
       " ('multi_vitamin', 4887),\n",
       " ('month_ago', 4870),\n",
       " ('green_coffee_bean_extract', 4603),\n",
       " ('great_product!.', 4583),\n",
       " ('exactly_what', 4504),\n",
       " ('come_back', 4417),\n",
       " ('raspberry_ketone', 4414),\n",
       " ('look_forward', 4396),\n",
       " ('every_morning', 4219),\n",
       " ('diet_and_exercise', 4201),\n",
       " ('get_rid', 4201),\n",
       " ('week_ago', 4127),\n",
       " ('people_who', 4125),\n",
       " ('6_month', 3940),\n",
       " ('blood_sugar', 3938),\n",
       " ('throughout_the_day', 3937),\n",
       " ('500_mg', 3719),\n",
       " ('second_bottle', 3601),\n",
       " ('little_bit', 3570),\n",
       " ('those_who', 3559),\n",
       " ('appetite_suppressant', 3509),\n",
       " ('by_far', 3460),\n",
       " ('on_an_empty', 3397),\n",
       " ('vitamin_d3', 3313),\n",
       " ('raspberry_ketones', 3300),\n",
       " ('health_benefit', 3286),\n",
       " ('right_away', 3258),\n",
       " ('long_term', 3252),\n",
       " ('joint_pain', 3218),\n",
       " ('energy_boost', 3198),\n",
       " ('green_tea', 3190),\n",
       " ('hot_flash', 3082),\n",
       " ('rather_than', 3081),\n",
       " ('loose_weight', 3036),\n",
       " ('gain_weight', 2963),\n",
       " ('before_bed', 2921),\n",
       " ('1000_mg', 2666),\n",
       " ('do_the_trick', 2613),\n",
       " ('digestive_system', 2604),\n",
       " ('depend_on', 2581),\n",
       " ('anything_else', 2563),\n",
       " ('fat_burner', 2518),\n",
       " ('clear_up', 2498),\n",
       " ('vitamin_e', 2489)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the 100 most frequent paired words\n",
    "paired_words_frq = Counter([word for word in trigrams_flat if '_' in word])\n",
    "paired_words_frq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('overturn_conventional_wisdom', 1),\n",
       " ('eat&#8221_the_wrong_combo', 1),\n",
       " ('tub_of_humus_with_veggie', 1),\n",
       " ('veep_university', 1),\n",
       " ('consumer_of_cookies!!it', 1),\n",
       " ('portion_veep_university---', 1),\n",
       " ('expereienc_with_veep', 1),\n",
       " ('visual_representation_veep', 1),\n",
       " ('veep_lookcut_program', 1),\n",
       " ('fitness_fanatic_veep_university', 1),\n",
       " ('outdoor_enthusiast_mtn', 1),\n",
       " ('mountain_biking_rowing', 1),\n",
       " ('trx_training', 1),\n",
       " ('lilttle_longer', 1),\n",
       " ('double_decker_cheeseburger', 1),\n",
       " ('marathon_and_a_tri_atholon', 1),\n",
       " ('8220_recommended&#8221', 1),\n",
       " ('trade_show&#8230', 1),\n",
       " ('go!upon_arrival', 1),\n",
       " ('hydroxycitric_acid_hca).this', 1),\n",
       " ('sharp_edges2', 1),\n",
       " ('crash_dieting).in_conclusion', 1),\n",
       " ('nuline_nutritionals_and_tomoson', 1),\n",
       " ('wishful_thinking!ftc_disclosure', 1),\n",
       " ('savor_the_taste).as', 1),\n",
       " ('34;healthy_fat&#34', 1),\n",
       " ('atrail_fibrillationso', 1),\n",
       " ('holy_cr*p', 1),\n",
       " ('w700_and_the_ubersurge', 1),\n",
       " (\"bootle_of_uberday_women_'s\", 1),\n",
       " ('detail_and_a_superior_product!paula', 1),\n",
       " ('deem_morbidly_obese', 1),\n",
       " ('ever!!!highly_recommended', 1),\n",
       " ('bioperene_a_black_pepper', 1),\n",
       " ('neal_a_previous_reviewer', 1),\n",
       " ('george_flansbaum_whom', 1),\n",
       " ('dynamic_nutrition_brand.http://www.amazon.com/pure-forskohlii-standardized-recommended-manufactured/dp/b00k6nzslm/ref=sr_1_3?s=hpc&ie;=utf8&qid;=1405359371&sr;=1-3&keywords;=forskolin',\n",
       "  1),\n",
       " ('young_chronologically', 1),\n",
       " ('side_effects).this', 1),\n",
       " ('onelife_pharma_sound', 1),\n",
       " ('hole_tighter', 1),\n",
       " ('melissa_jones', 1),\n",
       " ('coco_mak_seriously', 1),\n",
       " ('awful!!!._a_group', 1),\n",
       " ('i&#8217;m_assuming', 1),\n",
       " ('yeast_infection_every2', 1),\n",
       " ('a++standadrized_forskolin_excellent!.', 1),\n",
       " ('athlete_and_grappler', 1),\n",
       " ('currently_a_brazilian_jiujitsu', 1),\n",
       " ('minus_the_jitters--', 1),\n",
       " ('wrestling_and_bjj', 1),\n",
       " ('garcinia_cambhogia', 1),\n",
       " ('flood_with_34;snake_oil.&#34', 1),\n",
       " ('hydrolysis_the_protease_enzym', 1),\n",
       " ('camp_inducement', 1),\n",
       " ('air_passage_vasodilation', 1),\n",
       " ('belly_fat!).i', 1),\n",
       " ('amateur_muay_thai_tournament', 1),\n",
       " ('hormone_sensitive_lipase&#8212;which', 1),\n",
       " ('newly_devote', 1),\n",
       " ('deep_hallow_breath', 1),\n",
       " ('34;daily_supplements&#34', 1),\n",
       " ('happier!._there&#8217;s', 1),\n",
       " ('ad_lib', 1),\n",
       " ('sound_8220;hokey&#34', 1),\n",
       " ('rattly_and_uncomfortable', 1),\n",
       " ('burn_fat_and_dlower', 1),\n",
       " ('effectivity_lipolysis', 1),\n",
       " ('rebecca_peagler', 1),\n",
       " ('medical_conditionsthe', 1),\n",
       " ('forskohlli_root', 1),\n",
       " (\"luckily_it't\", 1),\n",
       " ('minus_1.5_lbs)&#9830', 1),\n",
       " ('60-day_trail', 1),\n",
       " ('considerable_drop)fyi', 1),\n",
       " ('8730_surprised_me', 1),\n",
       " ('red_meat_diet!with', 1),\n",
       " ('amazing!https://www.youtube.com_channel_uctciyg3wusbfxkgyjfpz8og', 1),\n",
       " ('garcinic_cambogia_extract', 1),\n",
       " ('virtually_untreatable', 1),\n",
       " ('sample_set_of_naturily', 1),\n",
       " ('osteoarthritis_and_osteomalacia', 1),\n",
       " ('con_su_rodilla', 1),\n",
       " ('mucho_a_mi', 1),\n",
       " ('productmuy_buen_producto_ayuda', 1),\n",
       " ('sodium_free.&#34', 1),\n",
       " ('peanuts_or_tree', 1),\n",
       " ('countless_cortizone_shot', 1),\n",
       " ('tons_of_benefits!.', 1),\n",
       " ('34;clear_out&#34', 1),\n",
       " ('bri_nutrition&#8217;s_unconditional_guarantee', 1),\n",
       " ('dieting_pilling', 1),\n",
       " ('nutrition!._bri_nutrition', 1),\n",
       " ('garage_and_repaint_the_wall', 1),\n",
       " ('bri_nutrition_triphalia', 1),\n",
       " ('crave_34;sweets&#34_and_salty', 1),\n",
       " ('unhygienic_colon', 1),\n",
       " ('slouchy_and_drain', 1),\n",
       " ('stumble_upon_the_colonpro', 1),\n",
       " ('8220;bowel_issues&#8221_lately', 1)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 100 most infrequent paired words\n",
    "paired_words_frq.most_common()[::-1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203277"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paired_words_frq)   # number of paired words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 0 ns, total: 29.5 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# we need to learn the full vocabulary of the corpus to be modeled\n",
    "# learn the dictionary by iterating over all of the reviews\n",
    "trigram_dictionary = Dictionary(trigram_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter tokens that are very rare or too common from\n",
    "# the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "trigram_dictionary.filter_extremes(no_below=10, no_above=0.6)\n",
    "trigram_dictionary.compactify()   # remove gaps in id sequence after words that were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_dictionary.save('../vocab_dictionary.dict')     # save vocabulary dict locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_dictionary = Dictionary.load('../vocab_dictionary.dict')  # load the finished dictionary from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
