{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from functools import reduce\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cosine, mahalanobis\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = spacy.lang.en.STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data\n",
    "\n",
    "Only taking Vitamin D3 Supplements in this initial test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('./amzn_reviews/reviews_data_clean', delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_d3 = data.query('categories_clean ==  \"Health & Personal Care, Vitamins & Dietary Supplements, Vitamins, Vitamin D, D3\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Level: Cluster on the Set of Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_noun(blob):\n",
    "    '''\n",
    "    input:  text blob\n",
    "    output: returns only noun using spacy\n",
    "    notes:  this function returns only nouns that are at least 3 letters long and not in spacy\n",
    "            stop words\n",
    "    '''\n",
    "    blob = blob.lower()\n",
    "    doc = nlp(blob)\n",
    "    \n",
    "    # helper function so i can keep stringing on conditions like length and no stop words\n",
    "    def acceptable(word):\n",
    "        if len(word) > 2 and word not in STOP_WORDS:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    return [token for token in doc if acceptable(token) and (token.pos_=='NOUN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(filename):\n",
    "    '''\n",
    "    input: path to glove file\n",
    "    output: dictionary mapping word to embedding\n",
    "    '''\n",
    "    tmpDict = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line_list = line.rstrip().split(\" \")\n",
    "            key = line_list.pop(0)\n",
    "            # convert list of values to numpy array and add to dictionary\n",
    "            tmpDict[key] = np.array(line_list, dtype='float')\n",
    "\n",
    "    return tmpDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove\n",
    "glove_dict = load_glove('./emb/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 43s, sys: 17.7 s, total: 15min\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "# take nouns only\n",
    "%time test = (vit_d3.reviewText.apply(lambda x : ret_noun(x)))\n",
    "\n",
    "# take the set of all words\n",
    "test_set = reduce(lambda x, y : x | y, test.apply(lambda x : set(x)))\n",
    "\n",
    "# list of words\n",
    "words_avail = list(glove_dict.keys())\n",
    "\n",
    "# list of glove arrays from words\n",
    "#test_glove = [glove_dict[w.string] for w in test_set if w.string in words_avail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write test_glove to pickle since it takes a while\n",
    "with open('test_glove', 'wb') as fp:\n",
    "    pickle.dump(test_glove, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the pickle\n",
    "test_glove = pickle.load( open( \"test_glove\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(20).fit(test_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "# returns the top 5 words closest to each cluster center for aid interpretation\n",
    "cluster_term = []\n",
    "for cluster in kmeans.cluster_centers_:\n",
    "    # find nearest word in glove\n",
    "    nearest = 1000\n",
    "    nearest_k = []\n",
    "    for k,v in glove_dict.items():\n",
    "        curr_dist = cosine(v, cluster)\n",
    "        if curr_dist < nearest:\n",
    "            nearest = curr_dist\n",
    "            if len(nearest_k) < 5:\n",
    "                nearest_k.append(k)\n",
    "            else:\n",
    "                nearest_k.pop(0)\n",
    "                nearest_k.append(k)\n",
    "    cluster_term.append(nearest_k)\n",
    "\n",
    "print(cluster_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance: worthless\n",
    "cluster_term = []\n",
    "for cluster in kmeans.cluster_centers_:\n",
    "    # find nearest word in glove\n",
    "    nearest = 1000\n",
    "    nearest_k = []\n",
    "    for k,v in glove_dict.items():\n",
    "        curr_dist = np.sqrt(np.sum((v - cluster)**2))\n",
    "        if curr_dist < nearest:\n",
    "            nearest = curr_dist\n",
    "            if len(nearest_k) < 5:\n",
    "                nearest_k.append(k)\n",
    "            else:\n",
    "                nearest_k.pop(0)\n",
    "                nearest_k.append(k)\n",
    "    cluster_term.append(nearest_k)\n",
    "\n",
    "print(cluster_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
